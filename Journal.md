# Reflection three
I had a lot of thoughts this week, so I’ve tried to group them as effectively as possible instead of giving you something more stream of consciousness. Read in order, or skip through the following sections to the parts that interest you:
* [Advances in problem-solving](#Advances-in-problem-solving)
* [Reflecting on the readings and my editorial choices](#Reflecting-on-the-readings-and-my-editorial-choices) 
* [Applying this course in the real world](#Applying-this-course-in-the-real-world)

## Advances in problem-solving
I feel like I accomplished a lot this week! Not only in terms of the assignment, but also in terms of my problem-solving. I had far more errors in comparison to last week, which was sometimes frustrating, but sometimes amazing (once I’d figured it out, of course!). For the majority of my errors, I was able to take a deep breath, walk away for a little bit, and fix them later. Of course, I still made silly mistakes – for example, when first uploading my data into OpenRefine I was confused by the fact that I didn’t have any column titles. After going through the assignment instructions a second time, I realized I’d forgotten to add them in my .csv file! Once I’d done that, things everything had changed. There are also still things that left me wanting a better solution, such as the database.io error many of my classmates also experienced: 

![databasic internal server error](https://github.com/sidxi/week-3/blob/master/Week3%20databasic.io%20server%20error.PNG)
or how – whenever I try to open Gephi – it gives me the following error message:

![Gephi error](https://github.com/sidxi/week-3/blob/master/Week%203%20OpenGL%20ES%20Error%20-%20Can%E2%80%99t%20find%20the%20name%20of%20Intel%20ICD%20Open%20GL%20driver.PNG)

My “solutions” for these were to use [Palladio](http://hdlab.stanford.edu/palladio/) (as suggested by Dr. Graham), and to click “okay” until the error message stopped impeding the program launching (it didn’t seem to change the way that Gephi worked), respectively. Not the most satisfying in terms of understanding _why_ something went wrong!

However, there were a two errors where I went from an initial “what on _earth_ is happening” reaction to understanding the problem and how I could fix it. First, when I was installing curl onto my Windows computer, I received the following error message: 

![No permission error](https://github.com/sidxi/week-3/blob/master/Week3%20Error%20-%20The%20current%20user%20does%20not%20have%20write%20permissions%20to%20the%20target%20environment.PNG)

After a quick search, I learned that Windows didn’t like that I was trying to make the changes as in individual user of the computer. In order to properly install curl, I had to open my Anaconda command prompt in Administrator mode, whereupon it worked perfectly:

![No permission fixed](https://github.com/sidxi/week-3/blob/master/Week3%20No%20permission%20error%20fixed.PNG)

(Now that I think about it, I wonder what would have happened if I’d installed wget in administrator mode. Would things have changed regarding my ability to use the program? Possibly something to try when I have a free moment!)

Second, when I installed Gephi and first tried to launch the program, I received the following error: *Cannot find Java 1.8 or higher*. I unfortunately didn’t take a screenshot of this error (which I’m totally kicking myself for – a major part of this learning process is documenting errors!). Nevertheless, I knew that I did in fact have the latest version of Java, because I’d had to install it to use OpenRefine. A quick search told me that I wasn’t alone in my problem, and it gave me an indication of how to fix this. By following C:\Program Files\Gephi-0.9.2\etc, I found the gephi.conf file, which contained Gephi’s configuration instructions. As per the instructions I was following, I opened it in Notepad and added the following – adapted – line to the top of the configuration instructions: 

**jdkhome="C:/Program Files (x86)/Java/jre1.8.0_251"**

The reason I had to adapt this line was because the fix was from several years ago, and the person who had solved the problem had a different version of Java installed. I hopped back into my program files to find my specific version of Java (jre1.8.0_251), and used that instead of their earlier version. Afterwards, I was able to open Gephi without receiving that error!

One area where I’m still not sure what went wrong is what was meant to happen between my dates in between the OpenRefine step and the Network configuration step. I asked the following question in the Discord:

![Week 3 Question](https://github.com/sidxi/week-3/blob/master/Week3%20date%20issue.PNG)

As you can see, I quickly found a kindred spirit in my confusion! While we had the same issue, we ultimately came to different solutions: they used the document provided by Dr. Graham (which didn’t have dates), while I went back in to OpenRefine, deleted the date column, then re-exported my cleaned data. Dr. Graham did chime in later saying that we could have used the .csv file with the dates, but I am happy to have learned a new feature of OpenRefine regardless. I would still like to know what went wrong, though.

## Reflecting on the readings and my editorial choices
Creating visual representations of data means that you are making deliberate choices that will shape how others interpret your work (and thus history). Whether this is the size of a node on a map, or the inclusion/exclusion of a site person, it can have an impact. For example, [James Baker (2017a)](https://cradledincaricature.com/2017/05/24/the-soft-digital-history-that-underpins-my-book/) discussed how their instincts lead them to exclude stationers from their map of satirical print business networks in Britain. This resulted in their realization that “stationer” was a far broader category then they originally realized, becoming “one of the main intellectual contributions of [his] book” (para 14). While these maps were ultimately excluded from his book, [Baker (2017b)](https://cradledincaricature.com/2017/06/06/the-hard-digital-history-that-underpins-my-book/) did include “corpus level quantitative” (para. 6) network analysis work to assert that caricaturists (in this location and time) created works designed to be commercially successful. 

Of course, I haven’t written a history book. However, I found myself in a similar position to Baker as I decided what to merge within my network, and what to leave alone. Some of the choices I made were simple (such as merging the many misspellings of “Ashbel Smith”), but others were more complex. One such inclusion/exclusion example that emerged for me this week was centered around two names: Lord Russel, and M.P. Russel. My prior knowledge and personal biases led me to remember that “M.P.” is short for “Member of Parliament,” and that during the 1800s those in government would be members of the ruling class. A quick search took me to Earl John Russell’s Wikipedia page, which told me that John Russell was both a Lord and an MP in the 1840s (when the correspondence occurred). Because of this, I was able to change the two to “Lord Russell [M.P.]”. Ultimately, Lord Russell [M.P.] was at the fringes of this network, and less important in the framework of the Texas correspondence. For me, however, he represents an editorial choice where I was able to link the digital history I was engaging with to other forms of history, showing how the two can intersect and inform each other. 

History is something I have always been casually interested in. I’ve read a decent amount of it, both inside and outside academic contexts. The only times I have written history, it’s been in an academic context. Overall, history has been presented to me, and I have presented it, in a primarily linear fashion. The courses I have taken have moved from “the beginning” (usually a start date chosen because of a particular significance) to “the end” (either an end date chosen once again due to a particular significance, or arriving at the present – where history is no longer “history” but rather “history in the making”). Something that occurred for me this week was a shift in my understanding of how history could be presented. The ability to create networks of history illustrated how this kind of data visualization can point to new kinds of connections and show interconnected relationships that (may have) shaped choice. In the case of the Texas correspondence, we can see a variety of key players emerge alongside two divided communities. This visualization could provide a jumping off point for a myriad of questions, including the following: why did these groups structure themselves in this particular manner? Is anyone given an undeserved position of prominence? Who is missing from this narrative? Drawing from other previously established historical knowledge about this location and time period will be essential to answering these questions, combining “regular” historical work with digital history.

Of course, network visualizations aren’t always the correct choice, because the very act of making a network such as this one readable means that the data will no longer be mathematically correct. While this type of data presentation does introduce bias, other forms of historical documentation also introduce bias. There is no unbiased way to do history, no formula that can be followed to reveal the genuine truth of the matter. Even “facts,” such as who won a particular war, can be up for debate – one that immediately springs to mind is [the Battle of 1812](https://nationalpost.com/war-of-1812/tallying-the-winners-and-losers-of-the-war-of-1812). Ultimately, both regular and digital history have value because they offer different perspectives and provide tools that can be used in conjunction with each other. And network visualization, when used appropriately, is a powerful form of digital history that can substantiate a historian’s interpretation of a particular past.

## Applying this course in the real world
This week, I had the delightful opportunity to use some of what we’re learning in this class for non-academic purposes. My mother works with a variety of elite athletes, including paralympic athletes. As a part of her job, she often creates and/or collaborates on infographics that communicate key information to her athletes. While she distributes them as PDFs, she frequently has to reformat this information for two visually impaired athletes she works with because their screen-reading technology isn’t PDF-compatible. This is something that takes her upwards of 20 minutes to do, and while that may not seem like a lot of time, it’s a task she finds frustrating. I wondered if I could use OCR to make that process quicker and easier for her, and so I asked her to send me the infographic she was hoping to send out this week.<sup>1</sup> After I’d converted it into a jpeg, I used OCR to pull the text from the image. While the end result wasn’t perfect (a few words had to be corrected slightly), this process took me just over 5 minutes, and it was far easier than copying and pasting from each individual text box in the infographic. Ultimately, I loved that I was able to use something I’d _just_ learned to help out my mom and her athletes. Ensuring that resources are accessible is something I’m passionate about, and being able to use my new skills to do so only further cemented the value of this class to me. 

<sup>1</sup> Unfortunately, this information is proprietary, so I can’t include it on my public repo! If you’d like to see the image I used and the text I generated, shoot me an email. 
